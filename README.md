<<<<<<< HEAD
# ðŸ—£ï¸ Vaani â€” Real-Time Audio Intelligence (Luddy Hackathon 2025)

**Vaani** is an advanced real-time audio processing tool built during the **Luddy Hackathon 2025**. It transforms both live and recorded audio into structured, searchable, and intelligent transcripts. From transcription and speaker diarization to summarization and sentiment analysis â€” Vaani makes audio data instantly useful.

---

## ðŸš€ Key Features

- ðŸŽ™ï¸ **Live & File-based Transcription** using **Fast-Whisper**
- ðŸ§‘â€ðŸ¤â€ðŸ§‘ **Speaker Diarization** using **Distilled-Whisper** and **PyAnnote-Audio**
- ðŸ’¬ **Summarization & Sentiment Analysis** using **Hugging Face Transformers**
- â“ **Question Answering (QnA)** from transcript content
- ðŸ§  Smart chunking for low-latency real-time feedback
- ðŸŒ **Gradio Interface** for seamless interaction

---

## ðŸ“ Project Structure

```
Vaani_LuddyHack/
â”‚
â”œâ”€â”€ app.py                 # Main Gradio interface and orchestrator
â”œâ”€â”€ config.py              # Configuration handling, API key loading, and utility constants
â”œâ”€â”€ live_transcription.py  # Handles real-time audio input and Fast-Whisper transcription
â”œâ”€â”€ summarization.py       # Summarization, sentiment analysis, and QnA using Hugging Face models
â”œâ”€â”€ requirements.txt       # All required packages
â””â”€â”€ .env                   # Stores your secret API keys (ignored in Git)
```

---

## ðŸ”§ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/DaniManas/Vaani_LuddyHack.git
cd Vaani_LuddyHack
```

### 2. Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate      # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure API Keys

Create a `.env` file in the root directory with the following content:

```
GROQ_API_KEY=your_groq_api_key_here
HUGGINGFACE_TOKEN=your_huggingface_token_here
```

> ðŸ” You may also need other authentication (e.g., for PyAnnote or WhisperX if using hosted models). Include those as needed.

âš ï¸ **Do not commit your `.env` file**. It contains sensitive keys.

### 5. Launch the App

```bash
python app.py
```

> Gradio will open a local web app in your browser. Start using Vaani immediately!

---

## ðŸ§ª Example Use Cases

- ðŸŽ“ Transcribing and summarizing lectures or webinars
- ðŸ§‘â€ðŸ’¼ Real-time meeting notes with speaker-wise segmentation
- ðŸŽ™ï¸ Podcast processing and topic extraction
- ðŸ•µï¸â€â™‚ï¸ Investigative conversation analysis with sentiment breakdown
- ðŸ“Š Generating QnA insights from long audio interviews

---

## ðŸŒ Tech Stack

- ðŸ§  [Fast-Whisper](https://github.com/guillaumekln/faster-whisper) â€” Lightweight Whisper model for fast transcription
- ðŸ§‘â€ðŸ¤â€ðŸ§‘ [WhisperX](https://github.com/m-bain/whisperx) â€” Alignment & Diarization for Whisper
- ðŸ”Š [PyAnnote-Audio](https://github.com/pyannote/pyannote-audio) â€” Speaker diarization from pretrained models
- ðŸ’¬ [Hugging Face Transformers](https://huggingface.co/) â€” For summarization, sentiment, and Q&A
- ðŸŒ [Gradio](https://www.gradio.app/) â€” Fast and interactive frontend
- ðŸ§° PyDub, FFmpeg, Torch â€” Audio preprocessing and model support

---

## ðŸ“œ License

This project is licensed under the [MIT License](LICENSE).

---

## ðŸ™ Acknowledgements

- [Fast-Whisper](https://github.com/guillaumekln/faster-whisper) for efficient transcription
- [WhisperX](https://github.com/m-bain/whisperx) for alignment and diarization
- [PyAnnote](https://github.com/pyannote/pyannote-audio) for speaker diarization
- [Hugging Face](https://huggingface.co/) for state-of-the-art NLP models
- [Gradio](https://www.gradio.app/) for rapid UI development

=======
# Vaani---An-AI-powered-meeting-assistant
>>>>>>> 5db2977004382a8974588327b80be061c04b8db7
